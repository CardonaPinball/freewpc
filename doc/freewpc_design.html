
<h1>FreeWPC : Software for Controlling WPC Pinball Machines</h1>
<p><i>
Brian Dominy<br>
brian@oddchange.com<br>
</i></p>

<p>This paper describes FreeWPC, a replacement operating system for
Bally/Williams pinball machines utilizing the Williams Pinball
Controller (WPC) chip.  This includes all pinballs made by the
company between 1990-1999, starting with <i>Funhouse</i> and
ending with <i>Cactus Canyon</i>.

<p>FreeWPC is a work-in-progress, with much room for improvement, so
what is described here may not totally match the most recent
implementation.

<h2>The Hardware</h2>

<p>The WPC chip is essentially a giant address decoder that maps
a bunch of peripheral devices into the address space of the CPU, a
Motorola 6809.  By reading/writing addresses between $3F00 and $3FFF,
the CPU is able to access the peripherals.  This includes all of
the playfield switches, the solenoids, the lamps, etc.  It also
includes a number of other devices like the real-time clock and
a bit shifter.  Earlier generations of Williams pinballs implement
a lot of the I/O in custom TTL logic like PIAs.  The WPC is a
single ASIC.

<p>Also mapped into the 64KB address space are the dot matrix
controller pages.  The controller contains memory for 16 full screens,
and can be programmed to show any one of them at a time.  Up to 2
of the pages can be mapped into the 6809 address space at $3800 and
$3A00.

<p>RAM is located at the lowest addresses, between $0000 and $1FFF, for
a total of 8KB.

<p>The CPU board supports up to 1MB of ROM space for program code and
constant data.  Because the 6809 can only address a total of 64KB at
a time, a <b>paging mechanism</b> is used.  The upper 32KB is mapped
from $8000 to $FFFF permanently.  Any other 16KB of the ROM can be
mapped from $4000 to $7FFF, by writing to the WPC's <i>ROM page
register</i>.

<h2>Requirements</h2>

<p>There are numerous ways to approach the construction of an
embedded system.  Here are the some of the requirements that have
influenced the design of FreeWPC:

<ul>
<li><b>It must provide realtime capabilities.</b>  People don't expect
machines to miss switch closures, in the way that Windows users sometime
experience moments where the system "freezes".  Also, some operations
require extremely fine timing control, like the pulsing of a solenoid,
which needs millisecond-level control.  (Modern desktop operating
systems typically can only provide 10ms granularity, by comparison.)
<li><b>It needs multitasking.</b>  Machines have to manage lots of
physical devices at the same time.  Switches need to be polled at the
same time as the sounds, lights, and display are updated.  At a
higher layer, game rules often involve multiple "modes" running at
the same time.
<li><b>It must cope with a small amount of RAM.</b>  8KB is not a lot
of room to work with.  Keeping dynamic data structures as small as
possible is a challenge.
<li><b>It should be written in C as much as possible.</b>  This is
a requirement I imposed on the system myself.  Software engineers from
Williams have repeatedly indicated that they wrote the games directly
in assembly language.  In some ways this is better, since the developer
has completely control of what the CPU is doing.  Good compilers were
not available for the 6809 back in 1990, so it was the only available
choice when WPC was first developed.  Today, there was a gcc port for
the 6809 which, although I was skeptical at first, was adequate
enough to get the project rolling.  Using C allows more people to get
involved in the project and understand what is going on.
</ul>

<h2>Scheduling</h2>

<p>FreeWPC contains a small microkernel which supports nonpreemptive, first-
come first-serve (FCFS) multitasking and multigranular soft realtime 
processes.  That is:

<ul>
<li>FreeWPC is a multitasking system, which provides the illusion of
multiple threads running in parallel.
<li>There are two classes of tasks, ordinary and realtime.  
<li>The realtime
tasks have priority and are scheduled at compile-time to one of several
periods (e.g. every 1ms, every 8ms, etc.)  Realtime tasks cannot sleep.
They are triggered to run based on the IRQ interrupt, which fires about
once per 1ms.
<li>The FCFS tasks take whatever CPU time is remaining.  Each task will
continue to run until it explicitly gives up control to the next FCFS
task (that's the nonpreemptive part).  These tasks can sleep.  They
can only be interrupted by the periodic realtime tasks.
</ul>

<p>This design is simple enough for what we need.  There is no
explicit support for multitask communications like queues or semaphores.
In most cases, locking support is not needed: the only time would be
when you need to synchronize between a realtime and an FCFS task.
The solution is for the FCFS task to disable the IRQ interrupt around the
critical section, since that keeps the realtime tasks from getting
scheduled.  These critical sections need to be kept extremely small,
though!

<p>The WPC chip drives the IRQ line of the 6809 to generate an
interrupt once every 976 microseconds...  The timing of the IRQ is
fairly accurate as it is derived from the 32Khz oscillator on the CPU
board.  Thus, the IRQ is used as the main timing source for the kernel.
Realtime functions are called directly from the IRQ handler.  FCFS
tasks which are sleeping have their "time-until-ready-to-run" counters
updated based on the number of IRQs that have happened.

<p>It is possible to compute the percentage of time spent running
at the IRQ level, since the functions are fixed.  The more efficient
the realtime functions, the more time available for other tasks.
There is a fine balance to be found here.  Realtime functions need
to run every so often, <b>but not more often than that.</b>  Polling
more frequently than necessary is simply a waste of time, for
example.

<p>Realtime tasks are scheduled in terms of "IRQ ticks".  If a function
needs to run every 8ms, and the IRQ occurs once every 1ms, then the
function should only be called once out of every 8 IRQs.  However,
the functions should be scheduled in such a way that the total
duration of realtime calls during a single IRQ does not exceed the
time between IRQs; when this happens, the realtime guarantee has failed.

<h2>Modularity</h2>

<p>The system is designed to be as modular as possible.  Each logical
hardware component is managed by a different module in the kernel,
which normally translates to a single .c file in the kernel directory.
The kernel provides standard APIs for accessing the hardware.  "User code"
should never directly write to a WPC hardware register.

<p>Most hardware modules provide a periodic realtime function that does
the very low-level I/O, e.g. polling switches or redrawing the lamp matrix.
FCFS code rarely will touch the hardware directly; instead, it will either
queue the request (if it is to drive an output), or read from an internal
buffer (if it is a read request -- which will retrieve the last value
polled by the realtime function).

<p>There is also the modularity between the kernel and the user code.  Each
machine can define additional functions that need to be invoked when certain
events occur.  These are implemented as callback functions.  This allows
the kernel to be "extended" to suit the needs of a particular machine.
Also, there are a number of constants which are machine-specific.  Each
machine has a "config.h" file that contains all of those values.

<h2>Inputs and Outputs</h2>

<p>Aside from the multitasking, the kernel is mostly concerned with the
management of hardware resources: input and output devices.  Here is
where the differences between an emulator like PinMAME and actual hardware
vastly differ.  What has been implemented so far works pretty well in
the emulations, though.

<p>The major input devices are, of course, the various switches and
buttons.  There's also the DIP switches on the CPU board, the real time
clock, and the AC zero-cross detection circuit.  Switches are the easiest
to describe because they work in theory in the simplest possible of way.
Every switch is just a binary input, either 1 (active) or 0 (inactive).

<p>Of course, it's much more complicated than that.  First and foremost
is the need for debouncing with the mechanical (non-opto) type switches,
in which a significant amount of vibration occurs upon closure, causing
the CPU to see tens of closures instead of one.  Debounce logic takes
the raw switch signal and filters it to produce a smoother, more binary
type signal.  Transitions only occur if they hold their new state for
a certain period of time (which may be dependent on the type of switch).

<p>Output devices like lamps and solenoids are just the opposite: they
are binary outputs, which in theory are logically on (1) or off (0).
The exact opposite of debouncing needs to be performed here, though:
to prevent fatigue of a coil, a logical "1" signal needs to be "bounced"
so that it is really only a "1" every so often, and "0" otherwise.
This is called "duty cycling".  The algorithm could be different depending
on the type of coil or duration of the pulse.

<p>Switches and lamps have an additional complicating factor in WPC: 
they can't all be addressed at the same time.  Instead, they are arranged
into an 8x8 matrix.  At any given time, only one column (8 switches or 8
lamps) is addressable for reading/writing.  Another register must first
be programmed with the column value to determine which of the 8 columns
it will be.  For lamps, this adds inherent duty cycling as no more than
8 of the lamps will ever be on at a time.

<p>Also for switches, there is the complication of optos, which are
normally closed and open when they become active.  Software must use
"backwards logic" on these.

<h2>Effect Management</h2>

<p>At a layer above the physical hardware, management must be provided
for output devices when there are multiple tasks wanting to access them.
The dot matrix, lamps, solenoids, and music playing can all be controlled
fairly easily, but if multiple tasks want to use them at the same time,
what do you do?

<p>The solution implemented in FreeWPC involves hardcoded priorities.
When a task wants to use a resource, it first tries to <i>allocate</i> that
resource, passing a priority value.  The allocation/free approach is
very simple to the way that files or other devices are opened/closed on
traditional UNIX systems.

<p>Only the task with the highest priority is allowed to use the
resource.  This usage is preemptive, unlike task scheduling: when a higher
priority task takes over control over a resource, the lower priority
task must stop using it immediately.  Likewise, when the higher priority
task is done, control should be returned to the lower priority task.

<p>This approach is implemented by using what computer scientists call
a <b>priority queue</b>.

<p>Priority queueing is often used in realtime operating systems for task
scheduling, but it is slightly different here.  Our FCFS tasks have no
concept of priority; they all run equally first-come, first-serve.  We
want to partition them into different sets based on the resources that they
need.  All tasks using the display would be in one set; all tasks requiring
the lamps would be in another set.  Tasks in different sets are disjoint
and can be scheduled independently.  However, within a single set, only
the single task with the highest priority gets to use that resource.

<p>This is how I think it should work in theory.  There are additional
complications.  What about tasks that require multiple resources, like
a jackpot animation that wants to drive the display, lamps, and make some
explosion sounds?  These are three distinct resources, and not all of them
may be available at the time of the effect.  In the current FreeWPC
approach, it would require three separate tasks to do all of these
things.  They could all have different priorities even.  So if the
lamps are busy, at least the other two things can happen.  For something
like a jackpot animation, this probably indicates a flaw in the priority
assignments, but for some effects, this might make sense.

<p>Also, consider the granularity of the resource.  In the simplest approach,
all of the lamps could be treated as a single resource, so you get all or
none of them.  But you could break it down further and manage each lamp
separately, so that a lamp effect might run but only be able to update
some of the lamps.  Today, FreeWPC treats the entire lamp matrix as one
resource.  The same goes for the entire dot matrix display; you either
get it or you don't.

<p>To implement the priority queueing properly, a task that wants to
implement some part of an effect needs to be standalone from any other
processing.  That way, that particular task can be stopped/started by
the kernel's resource management routines as priorities change.
Only the tasks that are actively controlling the resource will run.
The kernel simply remembers all of the tasks that have been queued up
which can't run currently.

<h2>Initialization</h2>

<p>Control begins by branching to RESET routine; the RESET vector at the
top of memory must be programmed with this address so the 6809 can
find it when it powers up.

<p>It is best not to make any assumptions about the values of I/O registers
immediately after booting.  Therefore, one of the first things that
normally happens in embedded systems is to program all of the registers
with sane values.

<p>It is unknown what the WPC bank switching register starts at, so to be
safe, make sure the reset routine resides in the non-paged portion of the
address space ($8000 to $FFFF).

<p>The 6809 has a direct page register, DP, which controls which 256 bytes
of RAM are addressed by the 1-byte form of effective address.  FreeWPC
places commonly used variables from $0000 to $00FF so DP should be
programmed to zero before accessing any RAM.

<p>During initialization, keep all interrupts disabled until all data
structures are setup that need to be in place for the interrupt handlers
to work properly.

<p>Each module of the kernel is initialized in turn, starting with the hardware
related modules and moving up to the software-only modules.  Once init
is complete, the kernel can enable interrupts and then jump into the
task scheduler.  The <b>first task</b> is started before doing so, to
ensure that there is some work to be done.  The first task takes care
of switch scheduling, which drives all of the other functions, and starts
up the initial attract mode.




